{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports üìö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape Data üåê"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select cities to get information about\n",
    "cities = ['Paphos', 'Rehovot','Rishon-Leziyyon','Larnaca','Nicosia','Limassol','Haifa','Jerusalem','Paris','Berlin','Amsterdam','Rome','Milan','Prague']\n",
    "htmls = []\n",
    "\n",
    "#Iterate over cities and scrape data\n",
    "for city in cities:\n",
    "    url = f'https://www.numbeo.com/cost-of-living/in/{city}?displayCurrency=EUR'\n",
    "    data = requests.get(url)\n",
    "\n",
    "    with open(f'{city}_numbeo.html','w+') as file:\n",
    "        file.write(data.text)\n",
    "        htmls.append(file.name)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn to Pandas DataFrames üêº & Clean üßº"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_names = []\n",
    "dfs = []\n",
    "\n",
    "for html in htmls:\n",
    "    # Use beautifulsoup to parse the html file\n",
    "    soup = BeautifulSoup(open(html),'html.parser')\n",
    "\n",
    "    # Look for the country name in hrefs\n",
    "    breadcrumb_links = soup.find_all('a', href=lambda href: href and 'country' in href, class_='breadcrumb_link')\n",
    "    country = breadcrumb_links[0].find('span', itemprop='name').text\n",
    "\n",
    "    # Create a variable to hold only the wanted table\n",
    "    table = soup.find('table', class_='data_wide_table new_bar_table')\n",
    "\n",
    "    # Search for the categories\n",
    "    category_divs = soup.find_all('div', class_='category_title')\n",
    "    categories = [div.text.strip() for div in category_divs]\n",
    "\n",
    "    # Turn into a DataFrame\n",
    "    df = pd.read_html(str(table))[0]\n",
    "\n",
    "    # Save current category to use in first df rows\n",
    "    current_category = categories.pop(0)\n",
    "    df['categories'] = current_category\n",
    "\n",
    "    # Iterate over the df and assign correct category\n",
    "    for index, row in df.iterrows():\n",
    "        if row['Edit'] == 'Edit':\n",
    "            # Assign the next category from the list\n",
    "            current_category = categories.pop(0) \n",
    "        # Assign the current category to the row\n",
    "        df.at[index, 'categories'] = current_category  \n",
    "\n",
    "    # Remove the rows with 'Edit' in the 'Edit' column\n",
    "    df = df[df['Edit'] != 'Edit']  \n",
    "\n",
    "    # Rename the Columns\n",
    "    df = df.rename(columns={'Restaurants': 'Item', 'Edit': 'Average_Price_in_Eur', 'categories': 'Category'})\n",
    "\n",
    "    # Turn average price to numeric and remove currency notation\n",
    "    df['Average_Price_in_Eur'] = pd.to_numeric(df['Average_Price_in_Eur'].str.replace('[^\\d.]', ''), errors='coerce')\n",
    "\n",
    "    # Remove commas from the Range column\n",
    "    df['Range'] = df['Range'].str.replace(',', '')\n",
    "\n",
    "    # Add a minimum and maximum columns from range column\n",
    "    df[['Minimum', 'Maximum']] = df['Range'].str.split('-', expand=True)\n",
    "    df['Minimum'] = pd.to_numeric(df['Minimum'], errors='coerce')\n",
    "    df['Maximum'] = pd.to_numeric(df['Maximum'], errors='coerce')\n",
    "\n",
    "    # Remove rows with NaNs in Range or Average Price\n",
    "    df = df.dropna(subset=['Range', 'Average_Price_in_Eur'])\n",
    "\n",
    "    # Save the city name in a new column\n",
    "    df['city'] = html.split('_')[0]\n",
    "\n",
    "    # Save the country name in a new column\n",
    "    df['country'] = country\n",
    "\n",
    "    # Save to csv file\n",
    "    df.to_csv(f\"{html.split('_')[0]}.csv\")\n",
    "\n",
    "    # Append df to df list\n",
    "    df_names.append((html, df))\n",
    "\n",
    "# Print the DataFrames\n",
    "for filename, df in df_names:\n",
    "    print(f\"DataFrame from file: {filename}\")\n",
    "    print(df)\n",
    "    print()\n",
    "\n",
    "\n",
    "# Keep all dfs in a list\n",
    "for filename, df in df_names:\n",
    "    dfs.append(df)\n",
    "\n",
    "# Union all cities to one table\n",
    "union_dfs = pd.concat(dfs,axis=0,ignore_index=True)\n",
    "\n",
    "# Check if item is present in all cities\n",
    "union_dfs['City_Count'] = union_dfs.groupby('Item')['city'].transform('nunique')\n",
    "union_dfs = union_dfs[union_dfs['City_Count'] == len(dfs)]\n",
    "    \n",
    "# Remove the 'City_Count' column\n",
    "union_dfs.drop('City_Count', axis=1, inplace=True)\n",
    "\n",
    "# Save the unioned table to csv file\n",
    "union_dfs.to_csv('union_dfs.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "410bfca62c59dbf09c46708e5b9e3ec83cc2c2acdaaf83d37a5d8185743cbbc6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
